import torch
import torch.nn as nn
from preprocess.marker_extractor import prepare_data
from model.autoencoder_lstm import LSTMAutoEncoder
import matplotlib.pyplot as plt


def detect_anomaly(video_path, model_path="trained_model.pth", threshold=None):
    print(f"ğŸ“¼ Analyzing {video_path}")
    
    # 1. ë°ì´í„° ì „ì²˜ë¦¬
    X = prepare_data(video_path, window_size=30)
    if len(X) == 0:
        print("âš ï¸ ìœ íš¨í•œ ì‹œí€€ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    model = LSTMAutoEncoder()
    model.load_state_dict(torch.load(model_path, map_location="cpu"))
    model.eval()

    # 3. ë³µì› ë° ì˜¤ì°¨ ê³„ì‚°
    criterion = nn.MSELoss(reduction='none')
    with torch.no_grad():
        reconstructed = model(X)
        loss = criterion(reconstructed, X)  # shape: (N, 30, 2)
        loss = loss.mean(dim=(1, 2))        # shape: (N,) â†’ ì‹œí€€ìŠ¤ë³„ MSE

    # 4. ì„ê³„ê°’ ì„¤ì • (ì—†ìœ¼ë©´ ìë™ ê³„ì‚°)
    if threshold is None:
        # í‰ê·  + 3 * í‘œì¤€í¸ì°¨ë¡œ ì´ìƒì¹˜ ê¸°ì¤€ ì„¤ì •
        threshold = loss.mean().item() + 3 * loss.std().item()

    print(f"ğŸ“Š Threshold: {threshold:.6f}")
    
    # 5. ì´ìƒ ì‹œí€€ìŠ¤ íŒë‹¨
    anomalies = (loss > threshold).numpy()
    for i, is_anomaly in enumerate(anomalies):
        status = "ğŸš¨ ì´ìƒ" if is_anomaly else "âœ… ì •ìƒ"
        print(f"[{i:03d}] MSE: {loss[i]:.6f} â†’ {status}")

    # 6. ì‹œê°í™”
    plt.figure(figsize=(10, 4))
    plt.plot(loss.numpy(), label="Reconstruction Error")
    plt.axhline(threshold, color='red', linestyle='--', label="Threshold")
    plt.title("Sequence-wise Reconstruction Error")
    plt.xlabel("Sequence Index")
    plt.ylabel("MSE")
    plt.legend()
    plt.tight_layout()
    plt.show()
